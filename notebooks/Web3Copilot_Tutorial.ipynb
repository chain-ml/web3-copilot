{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Web3Copilot Tutorial\n",
        "\n",
        "This notebook contains code snippets that will fill out missing components of the source code on the [`ethtoronto-tutorial` branch](https://github.com/chain-ml/web3-copilot/tree/ethtoronto-tutorial)."
      ],
      "metadata": {
        "id": "ACgEdxMG8bvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: TransctionDebuggerSkill"
      ],
      "metadata": {
        "id": "9-7Cx5qOKrrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init Skill\n",
        "\n",
        "We're inheriting the `SkillBase` class, so let's give our skill a name at the top of the `__init__` method:\n",
        "\n",
        "```python\n",
        "        super().__init__(name=\"txn_debugger\")\n",
        "```"
      ],
      "metadata": {
        "id": "3yz_wgxs9NNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure\n",
        "\n",
        "### Imports\n",
        "```python\n",
        "from dotenv import find_dotenv, get_key\n",
        "```\n",
        "\n",
        "### Complete the `_get_config` method:\n",
        "```python\n",
        "    def _get_config(self):\n",
        "        env_path = find_dotenv()\n",
        "\n",
        "        web3_config = {\n",
        "            \"rpc_url\": get_key(env_path, \"ETH_MAINNET_URL\"),\n",
        "            \"tenderly_api_key\": get_key(env_path, \"TENDERLY_API_KEY\"),\n",
        "            \"block_explorer_api_key\": get_key(env_path, \"ETHERSCAN_API_KEY\"),\n",
        "            \"etherscan_api\": get_key(env_path, \"ETHERSCAN_API\"),\n",
        "        }\n",
        "\n",
        "        return web3_config\n",
        "```"
      ],
      "metadata": {
        "id": "AVgue8yDMpwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete functions\n",
        "\n",
        "### Extract prompt from context\n",
        "\n",
        "In the `execute` method, assign the `query` variable as shown below:\n",
        "```python\n",
        "        query = context.chat_history.last_message.message\n",
        "```\n",
        "\n",
        "### Track Budget Consumptions\n",
        "\n",
        "1. In the `execute` method, anywhere after the POST request that fetches thet transaction trace, add the following:\n",
        "```python\n",
        "        budget.add_consumption(Consumption(1, \"call\", \"API_CALL\"), self.name)\n",
        "```\n",
        "\n",
        "2. Do the same in the `fetch_contracts` method:\n",
        "```python\n",
        "        budget.add_consumption(Consumption(1, \"call\", \"API_CALL\"), self.name)\n",
        "```"
      ],
      "metadata": {
        "id": "IHvkEeqs3cW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Return skill result\n",
        "\n",
        "At the end of `execute`, return this:\n",
        "```python\n",
        "        return self.build_success_message(\n",
        "            f\"{debug_context}\",\n",
        "            data=debug_context\n",
        "        )\n",
        "```"
      ],
      "metadata": {
        "id": "7m_WPR3477K3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: DocRetrievalSkill"
      ],
      "metadata": {
        "id": "FJAmr3Rm86Eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init skill\n",
        "Just as before, we need to give our skill a consistent name:\n",
        "\n",
        "```python\n",
        "        super().__init__(name=\"doc_retrieval\")\n",
        "```\n"
      ],
      "metadata": {
        "id": "Exhc8VGN9vO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete the `execute` function\n",
        "\n",
        "### Extract the prompt from `context`\n",
        "\n",
        "```python\n",
        "        query = context.chat_history.last_message.message\n",
        "```\n",
        "\n",
        "### Retrieve the documentation context\n",
        "\n",
        "```python\n",
        "        collection = self.db_client.get_or_create_collection(name=self.collection_name)\n",
        "        doc_context = self.retriever.retrieve_docs(query=query, collection=collection)\n",
        "```\n",
        "\n",
        "### Return skill result\n",
        "\n",
        "```python\n",
        "        return self.build_success_message(\n",
        "            f\"Results from {self.collection_name} in database retrieved\\n{doc_context}\",\n",
        "            data=doc_context\n",
        "        )\n",
        "```"
      ],
      "metadata": {
        "id": "t9RPp8g8-Ng9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Web3CopilotAgent"
      ],
      "metadata": {
        "id": "vCE4HjBW_EDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize skills\n",
        "\n",
        "\n",
        "### Documentation Retrieval\n",
        "\n",
        "1. As we will generate separate, unique PDFs for each web3 project, we should have a dedicated skill for them. These will be tracked by the `doc_retrieval_skills` dictionary. In the `init_skills` method, add the following code after the declaration of `doc_retrieval_skills`:\n",
        "\n",
        "```python\n",
        "        indices = list(create_file_dict(constants.DATA_DIR).keys())\n",
        "        for index in indices:\n",
        "            self.doc_retrieval_skills[index] = DocRetrievalSkill(\n",
        "                db_client=self.db_client,\n",
        "                collection_name=index,\n",
        "                retriever=self.retriever,\n",
        "            )\n",
        "```\n",
        "\n",
        "2. When we get our context message, we will have data that's unpresentable to users. Therefore we'll have to create another skill that converts the context messages from our main skill into plain English. That's where the `LLMSkill` class comes in. Right after the code above, create an LLM skill as follows:\n",
        "\n",
        "```python\n",
        "        self.dr_llm_skill = LLMSkill(\n",
        "            llm=self.llm,\n",
        "            system_prompt=self.load_system_prompt(\"doc_retrieval\"),\n",
        "            context_messages=self.build_context_message\n",
        "        )\n",
        "```\n",
        "\n",
        "### Transaction Debugging\n",
        "\n",
        "1. This skill is much simpler as it is very specific:\n",
        "```python\n",
        "        self.txn_debugger_skill = TransactionDebuggerSkill(\n",
        "            config=self.config\n",
        "        )\n",
        "```\n",
        "2. Create a corresponding LLMSkill for it:\n",
        "```python\n",
        "        self.txn_debugger_llm_skill = LLMSkill(\n",
        "            llm=self.llm,\n",
        "            system_prompt=self.load_system_prompt(\"txn_debugger\"),\n",
        "            context_messages=self.build_context_message\n",
        "        )\n",
        "```"
      ],
      "metadata": {
        "id": "L9mOh9L__bsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize chains\n",
        "\n",
        "Skills are contained in chains. The code has separate chains for each skill but the chain needs a `runner`. Let's populate that by adding the following snippets as parameters to the respective chains:\n",
        "\n",
        "```python\n",
        "                runners=[doc_retrieval_skill, self.dr_llm_skill],\n",
        "```\n",
        "\n",
        "```python\n",
        "                runners=[self.txn_debugger_skill, self.txn_debugger_llm_skill],\n",
        "```"
      ],
      "metadata": {
        "id": "dp1O4vKVB5MA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Templating: Prompts and Context Messages\n",
        "\n",
        "LLMs take prompts as input. You would have noticed that our LLMSkill instances take in `system_prompt` and `context_messages` as arguments. The system prompt is passed as an instruction to your skill while the context message is used to construct the final message sent to the LLMSkill with your skill's response data included.\n",
        "\n",
        "1. Birefly looking at the `load_system_prompt` method, you'll observe it references [Jinja2 template](https://jinja.palletsprojects.com/en/3.1.x/) files. Paste the following in each one:\n",
        "```\n",
        "{{ chat_history.user.last_message}}\n",
        "```\n",
        "\n",
        "2. In the `build_context_message` method, another template is being used. Carefully add the following where appropriate:\n",
        "```\n",
        "{{chain_history.last_message}}\n",
        "```\n",
        "```\n",
        "{{chat_history.user.last_message}}\n",
        "```\n",
        "\n",
        "3. Council applies data onto the templates using its `PromptBuilder` class. To use this for your skills, update the `build_context_message` as follows:\n",
        "\n",
        "```python\n",
        "        context_message_prompt = PromptToMessages(\n",
        "            prompt_builder=PromptBuilder(context_message_template)\n",
        "        )\n",
        "\n",
        "        messages = context_message_prompt.to_user_message(context)\n",
        "        return messages\n",
        "```\n"
      ],
      "metadata": {
        "id": "jFHAZKjRC3nT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Budgeting and Agent Execution\n",
        "\n",
        "LLMs like OpenAI's GPT models have a cost to use. Council allows you to set limits on your agent's execution. Budgets are time-based by default but can take in other types of \"consumptions\" that you want to limit such as 3rd party API requests. Recall that in our `TransactionDebuggerSkill` class, we added consumptions in the execution of our skill to track a certain type of consumption referred to as `API_CALL`. Here is how to set the budget limit on our agent in the `interact` method of the `Web3CopilotAgent` class:\n",
        "\n",
        "```python\n",
        "        api_call_limit = Consumption(10, \"call\", \"API_CALL\")\n",
        "\n",
        "        budget = Budget(\n",
        "            60,\n",
        "            limits=[\n",
        "                api_call_limit,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        result = self.agent.execute(context=self.context, budget=budget)\n",
        "```\n",
        "\n",
        "You can learn more about the budgeting [here](https://council.dev/en/latest/reference/runners/budget.html)."
      ],
      "metadata": {
        "id": "aMDe-mhlIBpp"
      }
    }
  ]
}